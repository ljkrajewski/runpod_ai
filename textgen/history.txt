    1  BASE='/workspace'
    2  INSTALLBASE="$BASE/oobabooga_linux"
    3  TGWBASE="$BASE/oobabooga_linux/text-generation-webui"
    4  RPBASE="$BASE/runpod_ai/textget"
    5  cd $BASE
    7  wget https://github.com/oobabooga/text-generation-webui/releases/download/installers/oobabooga_linux.zip
    8  unzip oobabooga_linux.zip
   10  cd $INSTALLBASE
   12  mkdir repositories
   13  cd repositories
   18  git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda
   19  cd GPTQ-for-LLaMa && python setup_cuda.py install
   22  cd $INSTALLBASE
   23  cp webui.py{,.bak}
   26  sed -i 's/gpuchoice = input("Input> ").lower()/gpuchoice = "a"/' webui.py
   27  sed -i 's/^        launch_webui()/#        launch_webui()/' webui.py
   29  bash start_linux.sh
   30  cd $TGWBASE/models
   39  git lfs install
       git clone --single-branch --branch main https://huggingface.co/TheBloke/Guanaco-13B-Uncensored-GPTQ  
   44  cd $TGWBASE
   45  pip install scipy
   47  cd $INSTALLBASE
   48  cp webui.py{.bak,}
   49  export OOBABOOGA_FLAGS="--listen --chat --auto-devices --model llama"
   52  bash start_linux.sh

